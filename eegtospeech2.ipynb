{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load EEG data (adjust path to your files)\n",
    "def load_eeg_data(file_path):\n",
    "    raw = mne.io.read_raw_fif(file_path, preload=True)  # Update for your file format\n",
    "    return raw\n",
    "\n",
    "# Preprocess EEG (ICA + Bandpass filter)\n",
    "def preprocess_eeg_data(raw):\n",
    "    raw.filter(0.5, 45, fir_design='firwin')  # Bandpass filter for the relevant frequency bands\n",
    "    \n",
    "    # Fit ICA for artifact removal\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=42, max_iter=800)\n",
    "    ica.fit(raw)\n",
    "    \n",
    "    # Identify and exclude EOG-related components (for eye artifacts)\n",
    "    eog_indices, _ = ica.find_bads_eog(raw)\n",
    "    ica.exclude = eog_indices\n",
    "    \n",
    "    raw_cleaned = ica.apply(raw)\n",
    "    return raw_cleaned\n",
    "\n",
    "# Feature extraction (spectral features)\n",
    "def extract_features(raw_cleaned):\n",
    "    # Apply fixed-length epochs (e.g., 2-second)\n",
    "    epochs = mne.make_fixed_length_epochs(raw_cleaned, duration=2, overlap=0.5)\n",
    "    features = epochs.get_data()  # Shape: (n_epochs, n_channels, n_timepoints)\n",
    "    \n",
    "    # Use FFT for frequency domain features (Power Spectral Density)\n",
    "    psd, freqs = mne.time_frequency.psd_welch(epochs, fmin=1, fmax=30)\n",
    "    psd = np.mean(psd, axis=2)  # Average over time\n",
    "    \n",
    "    # Normalize features (important for neural networks)\n",
    "    scaler = StandardScaler()\n",
    "    psd = scaler.fit_transform(psd)\n",
    "    \n",
    "    return psd\n",
    "\n",
    "# Load, preprocess, and extract features\n",
    "raw_data = load_eeg_data('path_to_eeg_data.fif')  # Replace with correct path\n",
    "raw_cleaned = preprocess_eeg_data(raw_data)\n",
    "features = extract_features(raw_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "\n",
    "# Build CNN-LSTM Hybrid Model\n",
    "def create_cnn_lstm_model(input_shape, output_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # CNN layers for spatial feature extraction\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(BatchNormalization())  # Normalize activations to stabilize training\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Bidirectional LSTM layers for temporal feature extraction\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Dropout to further reduce overfitting\n",
    "    model.add(Dense(output_classes, activation='softmax'))  # Softmax for multi-class output\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define input shape (number of features per input) and number of output classes\n",
    "input_shape = (features.shape[1], 1)  # Reshaped input features for CNN\n",
    "output_classes = len(labels)  # Number of possible output labels\n",
    "\n",
    "# Create and train the model\n",
    "model = create_cnn_lstm_model(input_shape, output_classes)\n",
    "model.summary()\n",
    "\n",
    "# Reshape data for CNN (add channel dimension)\n",
    "X_train_cnn = features.reshape((features.shape[0], features.shape[1], 1))\n",
    "\n",
    "# One-hot encode the labels\n",
    "labels = ['hello', 'goodbye', 'thanks', 'yes', 'no']  # Example labels\n",
    "y = np.array([label_to_index[label] for label in labels])  # Convert text labels to numerical index\n",
    "y_one_hot = to_categorical(y, num_classes=len(labels))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_cnn, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=25, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "# Function to convert text to speech\n",
    "def text_to_speech(text, filename=\"output.mp3\"):\n",
    "    speech = gTTS(text=text, lang='en', slow=False)\n",
    "    speech.save(filename)\n",
    "    os.system(f\"start {filename}\")  # For Windows, use the appropriate command for your OS\n",
    "\n",
    "# Predicting a new sample (replace with real-time input if needed)\n",
    "predicted_index = np.argmax(model.predict(X_test[0:1]), axis=1)[0]  # Example for first test sample\n",
    "predicted_text = labels[predicted_index]\n",
    "\n",
    "# Convert predicted text to speech\n",
    "text_to_speech(predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
